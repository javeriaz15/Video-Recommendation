{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPLjfc6Sw86e7lf57SJ3jv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWFyJwRYErjh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the raw dataset file on GitHub\n",
        "url = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/refs/heads/main/dataset/RS_Fakedata-7-35_users.json\"\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = pd.read_json(url)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "Cp1IzX_RM0Lb",
        "outputId": "87029065-a9d5-4d7e-885f-a4314c85d30e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id country         city state  age  \\\n",
            "0        1     USA  Los Angeles    CA   30   \n",
            "1        2     USA     New York    NY   30   \n",
            "2        3     USA  Los Angeles    CA   18   \n",
            "3        4  Canada      Toronto    ON   40   \n",
            "4        5  Canada    Vancouver    BC   18   \n",
            "\n",
            "                                    video_link      genre  watched  liked  \\\n",
            "0  https://www.youtube.com/watch?v=D4vN_5MBEog    hip hop      0.3  False   \n",
            "1  https://www.youtube.com/watch?v=7iqMNnzQPmY     ballet      0.5  False   \n",
            "2  https://www.youtube.com/watch?v=D4vN_5MBEog    hip hop      0.3   True   \n",
            "3  https://www.youtube.com/watch?v=p0VGHuaICyI  classical      0.1  False   \n",
            "4   https://www.youtube.com/shorts/fv5vCREiBMQ      k pop      0.1  False   \n",
            "\n",
            "   skipped  \n",
            "0     True  \n",
            "1     True  \n",
            "2     True  \n",
            "3     True  \n",
            "4     True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the video catalog file on GitHub\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/refs/heads/main/dataset/Video_catalog.json\"\n",
        "video_catalog = pd.read_json(url)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(video_catalog.head())\n"
      ],
      "metadata": {
        "id": "TJlcR93ANAuu",
        "outputId": "98b6fcbc-f3b8-4614-fc60-945ee2b785b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   video_id                                   video_link      genre  country  \\\n",
            "0         1  https://www.youtube.com/watch?v=D4vN_5MBEog    hip hop      USA   \n",
            "1         2  https://www.youtube.com/watch?v=7iqMNnzQPmY     ballet      USA   \n",
            "2         3  https://www.youtube.com/watch?v=p0VGHuaICyI  classical   Canada   \n",
            "3         4   https://www.youtube.com/shorts/fv5vCREiBMQ      k pop   Canada   \n",
            "4         5   https://www.youtube.com/shorts/kF0MRowRcIM    African  Nigeria   \n",
            "\n",
            "          city age_group  \n",
            "0  Los Angeles     18-35  \n",
            "1     New York     18-35  \n",
            "2      Toronto     35-50  \n",
            "3    Vancouver     18-25  \n",
            "4         Kano     35-50  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset as LightFMDataset\n",
        "from lightfm.evaluation import precision_at_k\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the user interaction data and video catalog\n",
        "user_data_url = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/refs/heads/main/dataset/RS_Fakedata-7-35_users.json\"\n",
        "video_catalog_url = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/main/dataset/Video_catalog.json\"\n",
        "user_data = pd.read_json(user_data_url)\n",
        "video_catalog = pd.read_json(video_catalog_url)\n",
        "\n",
        "# Configure logging to save error messages in a file\n",
        "logging.basicConfig(filename=\"svd_predictions.log\", level=logging.ERROR)\n",
        "\n",
        "# Set up Surprise model for collaborative filtering (SVD-based)\n",
        "reader = Reader(rating_scale=(0, 1))  # assuming binary (liked or not)\n",
        "surprise_data = Dataset.load_from_df(user_data[['user_id', 'video_link', 'liked']], reader)\n",
        "\n",
        "# Split the dataset into training and testing sets for SVD\n",
        "trainset, testset = train_test_split(surprise_data, test_size=0.2)\n",
        "svd_model = SVD()\n",
        "svd_model.fit(trainset)\n",
        "\n",
        "# Predict on the test set and calculate RMSE\n",
        "predictions = svd_model.test(testset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f\"SVD Model RMSE: {rmse}\")\n",
        "\n",
        "# Encode video genres, age, city, and state for content-based filtering in LightFM\n",
        "user_data['user_id'] = user_data['user_id'].astype(str)\n",
        "video_catalog['video_id'] = video_catalog['video_link'].factorize()[0]\n",
        "user_data['video_id'] = user_data['video_link'].map(video_catalog.set_index('video_link')['video_id'])\n",
        "user_ids = user_data['user_id'].unique()\n",
        "video_ids = video_catalog['video_id'].unique()\n",
        "\n",
        "# Prepare LightFM data with demographic information (age, location, genre)\n",
        "lfm_dataset = LightFMDataset()\n",
        "lfm_dataset.fit(users=(x for x in user_ids),\n",
        "                items=(x for x in video_ids),\n",
        "                item_features=(x for x in video_catalog['genre']))\n",
        "\n",
        "# Now build item features with genre, age, city, and state included\n",
        "item_features = lfm_dataset.build_item_features(\n",
        "    ((row['video_id'], [row['genre'], str(row['age']), row['city'], row['state']])\n",
        "     for _, row in video_catalog.iterrows())\n",
        ")\n",
        "\n",
        "# Train the LightFM model\n",
        "lfm_model = LightFM(loss='warp')\n",
        "(interactions, weights) = lfm_dataset.build_interactions(\n",
        "    ((str(row['user_id']), row['video_id']) for _, row in user_data.iterrows())\n",
        ")\n",
        "lfm_model.fit(interactions, item_features=item_features, epochs=30, num_threads=2)\n",
        "\n",
        "# Calculate Precision@5 for LightFM\n",
        "precision = precision_at_k(lfm_model, interactions, item_features=item_features, k=5).mean()\n",
        "print(f\"LightFM Precision@5: {precision}\")\n",
        "\n",
        "# Time decay function for adjusting ratings\n",
        "def time_decay(timestamp, decay_rate=0.001):\n",
        "    days_ago = (datetime.now() - datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S\")).days\n",
        "    return np.exp(-decay_rate * days_ago)\n",
        "\n",
        "# Apply time decay to liked ratings\n",
        "user_data['decayed_liked'] = user_data.apply(\n",
        "    lambda row: row['liked'] * time_decay(row['timestamp']) if row['liked'] else 0, axis=1\n",
        ")\n",
        "\n",
        "# Define engagement thresholds\n",
        "MIN_INTERACTIONS_FOR_ACTIVE = 5  # Minimum interactions to consider a user \"active\"\n",
        "HIGH_WATCH_THRESHOLD = 0.5  # Define what is considered high engagement (e.g., >50% watched)\n",
        "LOW_WATCH_THRESHOLD = 0.1  # Define what is considered low engagement (e.g., <10% watched)\n",
        "\n",
        "# Function to classify users based on activity patterns\n",
        "def classify_user_engagement(user_id):\n",
        "    user_interactions = user_data[user_data['user_id'] == user_id]\n",
        "    total_interactions = len(user_interactions)\n",
        "    avg_watch = user_interactions['watched'].mean()\n",
        "    total_liked = user_interactions['liked'].sum()\n",
        "    total_skipped = user_interactions['skipped'].sum()\n",
        "\n",
        "    # Determine user type based on interaction patterns\n",
        "    if total_interactions < MIN_INTERACTIONS_FOR_ACTIVE:\n",
        "        return \"new_user\"\n",
        "    elif avg_watch < LOW_WATCH_THRESHOLD and total_skipped >= total_interactions / 2:\n",
        "        return \"low_engagement_user\"\n",
        "    else:\n",
        "        return \"active_user\"\n",
        "\n",
        "# Get unique user IDs and classify each one\n",
        "user_profiles = {}\n",
        "for user_id in user_data['user_id'].unique():\n",
        "    profile = classify_user_engagement(user_id)\n",
        "    user_profiles[profile] = user_id\n",
        "\n",
        "# Define a function to generate recommendations based on factors and blend them\n",
        "def get_recommendations(user_id, n_recommendations=5, svd_weight=0.6, lightfm_weight=0.4):\n",
        "    recommendations = []\n",
        "\n",
        "    # SVD-based Recommendations (Interaction)\n",
        "    svd_recommendations = []\n",
        "    for video in video_catalog['video_link']:\n",
        "        try:\n",
        "            est_rating = svd_model.predict(user_id, video).est\n",
        "            svd_recommendations.append((video, est_rating * svd_weight))\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error predicting rating for user {user_id} and video {video}: {e}\")\n",
        "    svd_recommendations = sorted(svd_recommendations, key=lambda x: x[1], reverse=True)[:n_recommendations]\n",
        "\n",
        "    # LightFM Recommendations by Genre\n",
        "    user_index = lfm_dataset.mapping()[0].get(str(user_id))\n",
        "    if user_index is not None:\n",
        "        genre_scores = lfm_model.predict(user_index, np.arange(len(video_ids)), item_features=item_features)\n",
        "        genre_recommendations = sorted([(video_catalog.iloc[i]['video_link'], genre_scores[i])\n",
        "                                        for i in range(len(genre_scores))], key=lambda x: x[1], reverse=True)\n",
        "        recommendations += genre_recommendations[:n_recommendations]\n",
        "\n",
        "    # LightFM Recommendations by Age Group\n",
        "    age_features = lfm_dataset.build_item_features(\n",
        "        ((row['video_id'], [str(row['age'])]) for _, row in video_catalog.iterrows())\n",
        "    )\n",
        "    age_scores = lfm_model.predict(user_index, np.arange(len(video_ids)), item_features=age_features)\n",
        "    age_recommendations = sorted([(video_catalog.iloc[i]['video_link'], age_scores[i])\n",
        "                                  for i in range(len(age_scores))], key=lambda x: x[1], reverse=True)\n",
        "    recommendations += age_recommendations[:n_recommendations]\n",
        "\n",
        "    # LightFM Recommendations by Location (City and State)\n",
        "    location_features = lfm_dataset.build_item_features(\n",
        "        ((row['video_id'], [row['city'], row['state']]) for _, row in video_catalog.iterrows())\n",
        "    )\n",
        "    location_scores = lfm_model.predict(user_index, np.arange(len(video_ids)), item_features=location_features)\n",
        "    location_recommendations = sorted([(video_catalog.iloc[i]['video_link'], location_scores[i])\n",
        "                                       for i in range(len(location_scores))], key=lambda x: x[1], reverse=True)\n",
        "    recommendations += location_recommendations[:n_recommendations]\n",
        "\n",
        "    # Final Blended Recommendations, removing duplicates and limiting to top N\n",
        "    recommendations = list(dict.fromkeys([rec[0] for rec in recommendations]))\n",
        "    return recommendations[:n_recommendations]\n",
        "\n",
        "# Get recommendations for each user profile\n",
        "for profile, user_id in user_profiles.items():\n",
        "    print(f\"\\nRecommendations for {profile} (user {user_id}):\")\n",
        "    recommendations = get_recommendations(user_id, n_recommendations=5)\n",
        "    print(recommendations)\n",
        "\n",
        "# Example: Getting recommendations for a specific user by user input\n",
        "# Get unique user IDs from the dataset to handle any number of users dynamically\n",
        "unique_user_ids = user_data['user_id'].unique().tolist()\n",
        "\n",
        "# Prompt user to enter a valid user ID for recommendations\n",
        "user_input = input(f\"Enter a user ID from the following options: {', '.join(unique_user_ids)} for recommendations: \")\n",
        "\n",
        "# Check if the entered user ID is in the list of unique user IDs\n",
        "if user_input in unique_user_ids:\n",
        "    new_user_id = user_input\n",
        "    recommendations = get_recommendations(new_user_id, n_recommendations=5)\n",
        "    print(f\"Recommendations for user {new_user_id}:\", recommendations)\n",
        "else:\n",
        "    print(\"Invalid user ID. Please enter a valid user ID from the list.\")\n"
      ],
      "metadata": {
        "id": "cTOjfBFZkaAq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}