{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNycgy6VI3ZlHVXBSlv8OFx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWFyJwRYErjh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the raw dataset file on GitHub\n",
        "url = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/refs/heads/main/dataset/RS_Fakedata-7-35_users.json\"\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = pd.read_json(url)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "Cp1IzX_RM0Lb",
        "outputId": "87029065-a9d5-4d7e-885f-a4314c85d30e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id country         city state  age  \\\n",
            "0        1     USA  Los Angeles    CA   30   \n",
            "1        2     USA     New York    NY   30   \n",
            "2        3     USA  Los Angeles    CA   18   \n",
            "3        4  Canada      Toronto    ON   40   \n",
            "4        5  Canada    Vancouver    BC   18   \n",
            "\n",
            "                                    video_link      genre  watched  liked  \\\n",
            "0  https://www.youtube.com/watch?v=D4vN_5MBEog    hip hop      0.3  False   \n",
            "1  https://www.youtube.com/watch?v=7iqMNnzQPmY     ballet      0.5  False   \n",
            "2  https://www.youtube.com/watch?v=D4vN_5MBEog    hip hop      0.3   True   \n",
            "3  https://www.youtube.com/watch?v=p0VGHuaICyI  classical      0.1  False   \n",
            "4   https://www.youtube.com/shorts/fv5vCREiBMQ      k pop      0.1  False   \n",
            "\n",
            "   skipped  \n",
            "0     True  \n",
            "1     True  \n",
            "2     True  \n",
            "3     True  \n",
            "4     True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the video catalog file on GitHub\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/refs/heads/main/dataset/Video_catalog.json\"\n",
        "video_catalog = pd.read_json(url)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(video_catalog.head())\n"
      ],
      "metadata": {
        "id": "TJlcR93ANAuu",
        "outputId": "98b6fcbc-f3b8-4614-fc60-945ee2b785b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   video_id                                   video_link      genre  country  \\\n",
            "0         1  https://www.youtube.com/watch?v=D4vN_5MBEog    hip hop      USA   \n",
            "1         2  https://www.youtube.com/watch?v=7iqMNnzQPmY     ballet      USA   \n",
            "2         3  https://www.youtube.com/watch?v=p0VGHuaICyI  classical   Canada   \n",
            "3         4   https://www.youtube.com/shorts/fv5vCREiBMQ      k pop   Canada   \n",
            "4         5   https://www.youtube.com/shorts/kF0MRowRcIM    African  Nigeria   \n",
            "\n",
            "          city age_group  \n",
            "0  Los Angeles     18-35  \n",
            "1     New York     18-35  \n",
            "2      Toronto     35-50  \n",
            "3    Vancouver     18-25  \n",
            "4         Kano     35-50  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset as LightFMDataset\n",
        "from lightfm.evaluation import precision_at_k\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# Configure logging for errors only\n",
        "logging.basicConfig(filename=\"recommendation_system.log\", level=logging.ERROR)\n",
        "\n",
        "# Define URL parameters for flexibility\n",
        "USER_DATA_URL = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/refs/heads/main/dataset/RS_Fakedata-7-35_users.json\"\n",
        "VIDEO_CATALOG_URL = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/main/dataset/Video_catalog.json\"\n",
        "\n",
        "# Load data with error handling and retry mechanism\n",
        "def load_data(url):\n",
        "    try:\n",
        "        return pd.read_json(url)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading data from {url}: {e}\")\n",
        "        return pd.DataFrame()  # Return an empty DataFrame if loading fails\n",
        "\n",
        "user_data = load_data(USER_DATA_URL)\n",
        "video_catalog = load_data(VIDEO_CATALOG_URL)\n",
        "\n",
        "# Recommendation model weights\n",
        "SVD_WEIGHT = 0.6\n",
        "LIGHTFM_WEIGHT = 0.4\n",
        "\n",
        "# Collaborative filtering with Surprise SVD model\n",
        "reader = Reader(rating_scale=(0, 1))\n",
        "surprise_data = Dataset.load_from_df(user_data[['user_id', 'video_link', 'liked']], reader)\n",
        "trainset, testset = train_test_split(surprise_data, test_size=0.2)\n",
        "svd_model = SVD()\n",
        "svd_model.fit(trainset)\n",
        "\n",
        "# Predict and calculate RMSE\n",
        "predictions = svd_model.test(testset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "logging.info(f\"SVD Model RMSE: {rmse}\")\n",
        "\n",
        "# Encode video features for LightFM model\n",
        "video_catalog['video_id'] = video_catalog['video_link'].factorize()[0]\n",
        "user_data['user_id'] = user_data['user_id'].astype(str)\n",
        "user_data['video_id'] = user_data['video_link'].map(video_catalog.set_index('video_link')['video_id'])\n",
        "\n",
        "# Initialize LightFM dataset and build combined item features\n",
        "lfm_dataset = LightFMDataset()\n",
        "lfm_dataset.fit(users=(x for x in user_data['user_id'].unique()),\n",
        "                items=(x for x in video_catalog['video_id'].unique()),\n",
        "                item_features=(x for x in video_catalog['genre']))\n",
        "\n",
        "# Extract features with optimized apply function\n",
        "def extract_item_features(df, feature_cols):\n",
        "    return list(zip(df['video_id'], df[feature_cols].apply(lambda x: list(map(str, x)), axis=1)))\n",
        "\n",
        "feature_columns = ['genre', 'age', 'city', 'state']\n",
        "item_features = lfm_dataset.build_item_features(extract_item_features(video_catalog, feature_columns))\n",
        "\n",
        "# LightFM model training with reduced epochs\n",
        "lfm_model = LightFM(loss='warp')\n",
        "(interactions, weights) = lfm_dataset.build_interactions(\n",
        "    ((str(row['user_id']), row['video_id']) for _, row in user_data.iterrows())\n",
        ")\n",
        "lfm_model.fit(interactions, item_features=item_features, epochs=15, num_threads=4)\n",
        "\n",
        "# Precision@5 for LightFM\n",
        "precision = precision_at_k(lfm_model, interactions, item_features=item_features, k=5).mean()\n",
        "logging.info(f\"LightFM Precision@5: {precision}\")\n",
        "\n",
        "# Time decay function to adjust ratings\n",
        "def time_decay(timestamp, decay_rate=0.001):\n",
        "    days_ago = (datetime.now() - datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S\")).days\n",
        "    return np.exp(-decay_rate * days_ago)\n",
        "\n",
        "# Apply time decay to liked ratings\n",
        "user_data['decayed_liked'] = user_data.apply(\n",
        "    lambda row: row['liked'] * time_decay(row['timestamp']) if row['liked'] else 0, axis=1\n",
        ")\n",
        "\n",
        "# Calculate engagement thresholds\n",
        "MIN_INTERACTIONS_FOR_ACTIVE = int(user_data.groupby('user_id').size().quantile(0.5))\n",
        "HIGH_WATCH_THRESHOLD = user_data['watched'].quantile(0.75)\n",
        "LOW_WATCH_THRESHOLD = user_data['watched'].quantile(0.25)\n",
        "\n",
        "# Engagement classifier\n",
        "user_interactions_cache = user_data.groupby('user_id').apply(lambda x: {\n",
        "    'total_interactions': len(x),\n",
        "    'avg_watch': x['watched'].mean(),\n",
        "    'total_skipped': x['skipped'].sum()\n",
        "}).to_dict()\n",
        "\n",
        "def classify_user_engagement(user_id):\n",
        "    user_metrics = user_interactions_cache.get(user_id, {})\n",
        "    total_interactions = user_metrics.get('total_interactions', 0)\n",
        "    avg_watch = user_metrics.get('avg_watch', 0)\n",
        "    total_skipped = user_metrics.get('total_skipped', 0)\n",
        "\n",
        "    if total_interactions < MIN_INTERACTIONS_FOR_ACTIVE:\n",
        "        return \"new_user\"\n",
        "    elif avg_watch < LOW_WATCH_THRESHOLD and total_skipped >= total_interactions / 2:\n",
        "        return \"low_engagement_user\"\n",
        "    else:\n",
        "        return \"active_user\"\n",
        "\n",
        "user_profiles = {classify_user_engagement(user_id): user_id for user_id in user_data['user_id'].unique()}\n",
        "\n",
        "# Generate recommendations\n",
        "def get_recommendations(user_id, n_recommendations=5, svd_weight=SVD_WEIGHT, lightfm_weight=LIGHTFM_WEIGHT):\n",
        "    combined_scores = {}\n",
        "    unwatched_videos = video_catalog[~video_catalog['video_link'].isin(user_data[user_data['user_id'] == user_id]['video_link'])]\n",
        "\n",
        "    for video in unwatched_videos['video_link']:\n",
        "        try:\n",
        "            est_rating = svd_model.predict(user_id, video).est\n",
        "            combined_scores[video] = combined_scores.get(video, 0) + est_rating * svd_weight\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error predicting rating for user {user_id} and video {video}: {e}\")\n",
        "\n",
        "    user_index = lfm_dataset.mapping()[0].get(str(user_id))\n",
        "    if user_index is not None:\n",
        "        scores = lfm_model.predict(user_index, np.arange(len(video_catalog)), item_features=item_features)\n",
        "        for i, score in enumerate(scores):\n",
        "            video = video_catalog.iloc[i]['video_link']\n",
        "            combined_scores[video] = combined_scores.get(video, 0) + score * lightfm_weight\n",
        "\n",
        "    recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:n_recommendations]\n",
        "    return [rec[0] for rec in recommendations]\n",
        "\n",
        "unique_user_ids = user_data['user_id'].unique().tolist()\n",
        "user_input = input(f\"Enter a user ID from the following options: {', '.join(unique_user_ids)} for recommendations: \")\n",
        "\n",
        "if user_input in unique_user_ids:\n",
        "    recommendations = get_recommendations(user_input, n_recommendations=5)\n",
        "    print(f\"Recommendations for user {user_input}:\", recommendations)\n",
        "else:\n",
        "    print(\"Invalid user ID. Please enter a valid user ID from the list:\", unique_user_ids)\n",
        "\n"
      ],
      "metadata": {
        "id": "cTOjfBFZkaAq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}