{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMozZqWhd+/zQboQacP/Stq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWFyJwRYErjh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the raw dataset file on GitHub\n",
        "url = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/refs/heads/main/dataset/RS_Fakedata-7-35_users.json\"\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = pd.read_json(url)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "Cp1IzX_RM0Lb",
        "outputId": "87029065-a9d5-4d7e-885f-a4314c85d30e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id country         city state  age  \\\n",
            "0        1     USA  Los Angeles    CA   30   \n",
            "1        2     USA     New York    NY   30   \n",
            "2        3     USA  Los Angeles    CA   18   \n",
            "3        4  Canada      Toronto    ON   40   \n",
            "4        5  Canada    Vancouver    BC   18   \n",
            "\n",
            "                                    video_link      genre  watched  liked  \\\n",
            "0  https://www.youtube.com/watch?v=D4vN_5MBEog    hip hop      0.3  False   \n",
            "1  https://www.youtube.com/watch?v=7iqMNnzQPmY     ballet      0.5  False   \n",
            "2  https://www.youtube.com/watch?v=D4vN_5MBEog    hip hop      0.3   True   \n",
            "3  https://www.youtube.com/watch?v=p0VGHuaICyI  classical      0.1  False   \n",
            "4   https://www.youtube.com/shorts/fv5vCREiBMQ      k pop      0.1  False   \n",
            "\n",
            "   skipped  \n",
            "0     True  \n",
            "1     True  \n",
            "2     True  \n",
            "3     True  \n",
            "4     True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the video catalog file on GitHub\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/refs/heads/main/dataset/Video_catalog.json\"\n",
        "video_catalog = pd.read_json(url)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(video_catalog.head())\n"
      ],
      "metadata": {
        "id": "TJlcR93ANAuu",
        "outputId": "98b6fcbc-f3b8-4614-fc60-945ee2b785b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   video_id                                   video_link      genre  country  \\\n",
            "0         1  https://www.youtube.com/watch?v=D4vN_5MBEog    hip hop      USA   \n",
            "1         2  https://www.youtube.com/watch?v=7iqMNnzQPmY     ballet      USA   \n",
            "2         3  https://www.youtube.com/watch?v=p0VGHuaICyI  classical   Canada   \n",
            "3         4   https://www.youtube.com/shorts/fv5vCREiBMQ      k pop   Canada   \n",
            "4         5   https://www.youtube.com/shorts/kF0MRowRcIM    African  Nigeria   \n",
            "\n",
            "          city age_group  \n",
            "0  Los Angeles     18-35  \n",
            "1     New York     18-35  \n",
            "2      Toronto     35-50  \n",
            "3    Vancouver     18-25  \n",
            "4         Kano     35-50  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset as LightFMDataset\n",
        "from lightfm.evaluation import precision_at_k\n",
        "import numpy as np\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# Configure logging for enhanced debugging\n",
        "logging.basicConfig(filename=\"recommendation_system.log\", level=logging.INFO)\n",
        "\n",
        "# Define URL parameters for flexibility\n",
        "USER_DATA_URL = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/refs/heads/main/dataset/RS_Fakedata-7-35_users.json\"\n",
        "VIDEO_CATALOG_URL = \"https://raw.githubusercontent.com/javeriaz15/Video-Recommendation/main/dataset/Video_catalog.json\"\n",
        "\n",
        "# Load the user interaction data and video catalog\n",
        "logging.info(\"Loading user interaction data and video catalog.\")\n",
        "user_data = pd.read_json(USER_DATA_URL)\n",
        "video_catalog = pd.read_json(VIDEO_CATALOG_URL)\n",
        "\n",
        "# Configure collaborative filtering model with Surprise (SVD-based)\n",
        "reader = Reader(rating_scale=(0, 1))  # assuming binary (liked or not)\n",
        "surprise_data = Dataset.load_from_df(user_data[['user_id', 'video_link', 'liked']], reader)\n",
        "\n",
        "# Split the dataset and train SVD model\n",
        "logging.info(\"Training SVD model for collaborative filtering.\")\n",
        "trainset, testset = train_test_split(surprise_data, test_size=0.2)\n",
        "svd_model = SVD()\n",
        "svd_model.fit(trainset)\n",
        "logging.info(\"SVD model training completed.\")\n",
        "\n",
        "# Predict on the test set and log RMSE for model performance\n",
        "predictions = svd_model.test(testset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "logging.info(f\"SVD Model RMSE: {rmse}\")\n",
        "\n",
        "# Prepare LightFM dataset with combined item features for improved efficiency\n",
        "logging.info(\"Encoding video features for LightFM model.\")\n",
        "video_catalog['video_id'] = video_catalog['video_link'].factorize()[0]\n",
        "user_data['user_id'] = user_data['user_id'].astype(str)\n",
        "user_data['video_id'] = user_data['video_link'].map(video_catalog.set_index('video_link')['video_id'])\n",
        "\n",
        "# Initialize LightFM dataset\n",
        "lfm_dataset = LightFMDataset()\n",
        "lfm_dataset.fit(users=(x for x in user_data['user_id'].unique()),\n",
        "                items=(x for x in video_catalog['video_id'].unique()),\n",
        "                item_features=(x for x in video_catalog['genre']))\n",
        "\n",
        "# Build combined item features (genre, age, city, and state) for LightFM\n",
        "item_features = lfm_dataset.build_item_features(\n",
        "    ((row['video_id'], [row['genre'], str(row['age']), row['city'], row['state']])\n",
        "     for _, row in video_catalog.iterrows())\n",
        ")\n",
        "\n",
        "# Train LightFM model\n",
        "logging.info(\"Training LightFM model with combined item features.\")\n",
        "lfm_model = LightFM(loss='warp')\n",
        "(interactions, weights) = lfm_dataset.build_interactions(\n",
        "    ((str(row['user_id']), row['video_id']) for _, row in user_data.iterrows())\n",
        ")\n",
        "lfm_model.fit(interactions, item_features=item_features, epochs=30, num_threads=2)\n",
        "\n",
        "# Calculate Precision@5 for LightFM\n",
        "precision = precision_at_k(lfm_model, interactions, item_features=item_features, k=5).mean()\n",
        "logging.info(f\"LightFM Precision@5: {precision}\")\n",
        "\n",
        "# Time decay function to adjust ratings based on recency of interaction\n",
        "def time_decay(timestamp, decay_rate=0.001):\n",
        "    \"\"\"Apply a time decay based on the age of the interaction.\"\"\"\n",
        "    days_ago = (datetime.now() - datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S\")).days\n",
        "    return np.exp(-decay_rate * days_ago)\n",
        "\n",
        "# Apply time decay to liked ratings\n",
        "user_data['decayed_liked'] = user_data.apply(\n",
        "    lambda row: row['liked'] * time_decay(row['timestamp']) if row['liked'] else 0, axis=1\n",
        ")\n",
        "\n",
        "# Automatically calculate engagement thresholds\n",
        "logging.info(\"Calculating engagement thresholds based on dataset distribution.\")\n",
        "MIN_INTERACTIONS_FOR_ACTIVE = int(user_data.groupby('user_id').size().quantile(0.5))\n",
        "HIGH_WATCH_THRESHOLD = user_data['watched'].quantile(0.75)\n",
        "LOW_WATCH_THRESHOLD = user_data['watched'].quantile(0.25)\n",
        "\n",
        "def classify_user_engagement(user_id):\n",
        "    \"\"\"Classify user engagement as 'new_user', 'low_engagement_user', or 'active_user' based on interaction patterns.\"\"\"\n",
        "    user_interactions = user_data[user_data['user_id'] == user_id]\n",
        "    total_interactions = len(user_interactions)\n",
        "    avg_watch = user_interactions['watched'].mean()\n",
        "    total_skipped = user_interactions['skipped'].sum()\n",
        "\n",
        "    if total_interactions < MIN_INTERACTIONS_FOR_ACTIVE:\n",
        "        return \"new_user\"\n",
        "    elif avg_watch < LOW_WATCH_THRESHOLD and total_skipped >= total_interactions / 2:\n",
        "        return \"low_engagement_user\"\n",
        "    else:\n",
        "        return \"active_user\"\n",
        "\n",
        "# Get unique user IDs and classify each one\n",
        "user_profiles = {classify_user_engagement(user_id): user_id for user_id in user_data['user_id'].unique()}\n",
        "\n",
        "def get_recommendations(user_id, n_recommendations=5, svd_weight=0.6, lightfm_weight=0.4):\n",
        "    \"\"\"Generate blended recommendations using SVD and LightFM, balancing various features.\"\"\"\n",
        "    recommendations = []\n",
        "\n",
        "    # SVD-based Recommendations\n",
        "    svd_recommendations = []\n",
        "    for video in video_catalog['video_link']:\n",
        "        try:\n",
        "            est_rating = svd_model.predict(user_id, video).est\n",
        "            svd_recommendations.append((video, est_rating * svd_weight))\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error predicting rating for user {user_id} and video {video}: {e}\")\n",
        "    svd_recommendations = sorted(svd_recommendations, key=lambda x: x[1], reverse=True)[:n_recommendations]\n",
        "\n",
        "    # LightFM-based Recommendations by combined features\n",
        "    user_index = lfm_dataset.mapping()[0].get(str(user_id))\n",
        "    if user_index is not None:\n",
        "        scores = lfm_model.predict(user_index, np.arange(len(video_catalog)), item_features=item_features)\n",
        "        lightfm_recommendations = sorted(\n",
        "            [(video_catalog.iloc[i]['video_link'], scores[i] * lightfm_weight) for i in range(len(scores))],\n",
        "            key=lambda x: x[1], reverse=True\n",
        "        )\n",
        "        recommendations += lightfm_recommendations[:n_recommendations]\n",
        "\n",
        "    # Combine and limit to top recommendations, removing duplicates\n",
        "    recommendations = list(dict.fromkeys([rec[0] for rec in svd_recommendations + recommendations]))\n",
        "    return recommendations[:n_recommendations]\n",
        "\n",
        "# Get recommendations for each classified user profile\n",
        "for profile, user_id in user_profiles.items():\n",
        "    logging.info(f\"Generating recommendations for {profile} (user {user_id}).\")\n",
        "    recommendations = get_recommendations(user_id, n_recommendations=5)\n",
        "    print(f\"\\nRecommendations for {profile} (user {user_id}):\")\n",
        "    print(recommendations)\n",
        "\n",
        "# Get unique user IDs from dataset for input handling\n",
        "unique_user_ids = user_data['user_id'].unique().tolist()\n",
        "\n",
        "# Prompt user to enter a valid user ID for recommendations\n",
        "user_input = input(f\"Enter a user ID from the following options: {', '.join(unique_user_ids)} for recommendations: \")\n",
        "\n",
        "# Check if entered user ID is in list of unique user IDs\n",
        "if user_input in unique_user_ids:\n",
        "    recommendations = get_recommendations(user_input, n_recommendations=5)\n",
        "    print(f\"Recommendations for user {user_input}:\", recommendations)\n",
        "else:\n",
        "    print(\"Invalid user ID. Please enter a valid user ID from the list:\", unique_user_ids)\n"
      ],
      "metadata": {
        "id": "cTOjfBFZkaAq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}